{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "3.6.10\nCPU times: user 62 ms, sys: 4.2 ms, total: 66.2 ms\nWall time: 64.9 ms\n"}], "source": "%%time\nimport pandas as pd\nimport os, sys, time, json, re, string\n\nfrom pyspark import SparkContext, SparkConf, StorageLevel, keyword_only\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.ml.param.shared import HasInputCol, HasInputCols, HasOutputCol, HasOutputCols, Param\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer, NGram, CountVectorizer, StopWordsRemover\nfrom pyspark.ml.feature import VectorAssembler, PCA\n\nfrom pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\nfrom pyspark.ml import Pipeline, Transformer\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom platform import python_version\nprint(python_version())"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "CPU times: user 3 \u00b5s, sys: 0 ns, total: 3 \u00b5s\nWall time: 6.44 \u00b5s\n"}, {"data": {"text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-8866-m.asia-southeast1-b.c.weicheng.internal:4044\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        ", "text/plain": "<SparkContext master=yarn appName=PySparkShell>"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "%%time\nsc"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "CPU times: user 9.36 ms, sys: 0 ns, total: 9.36 ms\nWall time: 12 ms\n"}], "source": "%%time\nspark = SparkSession.builder \\\n        .appName(\"fakenews\") \\\n        .config(\"spark.master\", \"yarn\") \\\n        .config(\"spark.submit.deployMode\", \"cluster\") \\\n        .config(\"spark.driver.memory\", \"25g\") \\\n        .config(\"spark.executor.instances\", \"5\") \\\n        .config(\"spark.executor.cores\", \"4\") \\\n        .config(\"spark.executor.memory\", \"25g\") \\\n        .getOrCreate()"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "CPU times: user 18.6 ms, sys: 4.28 ms, total: 22.9 ms\nWall time: 7.35 s\n"}], "source": "%%time\nfakenews_path=\"gs://dataproc-6ca41800-27b4-47d5-abee-55c011dfa389-asia-southeast1/data/fake-news/\"\nfakenews_data_path = fakenews_path + \"two_million_rows_news_cleaned_2018_02_13_pyspark.csv\"\ndf_news = spark.read.format(\"com.databricks.spark.csv\") \\\n                    .option(\"header\", \"true\") \\\n                    .option(\"delimiter\", '#') \\\n                    .load(fakenews_data_path)\n\n# only keep type and content\ndf_news = df_news.select(\"type\", \"content\", \"domain\")\n# add binary label\ndf_news = df_news.withColumn(\"label\", F.when(F.col(\"type\") == 'fake', 1).otherwise(0))\n\n#remove empty content which will cause problem when transform the text\ndf_news = df_news.filter(df_news.content != \"\")\n\ndf_news_fake = df_news.filter(df_news.type == 'fake')\ndf_news_nonfake = df_news.filter(df_news.type != 'fake')\ndf_news = df_news_fake.union(df_news_nonfake)\n\n# split the dataset\ndf_train, df_test = df_news.randomSplit([0.8, 0.2], seed=666)\n\nparam_tuning = False"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\n# customized transformer class to manually extract some counting based text features\nclass ReviewContentTransformer(Transformer, HasInputCol, HasOutputCol):\n\n    @keyword_only\n    def __init__(self, inputCol=\"content\", outputCol=\"content_features\"):\n        super(ReviewContentTransformer, self).__init__()\n        kwargs = self._input_kwargs\n        self.setParams(**kwargs)\n\n    @keyword_only\n    def setParams(self, inputCol=None, outputCol=None):\n        kwargs = self._input_kwargs\n        return self._set(**kwargs)\n\n\n    def _transform(self, dataset):\n        @udf('double')\n        def f(s):\n            uppercase_count = 0\n            char_count = 0\n            for c in s:                \n                if c in string.ascii_uppercase:\n                    uppercase_count += 1\n                    char_count += 1\n                elif c in string.ascii_lowercase:\n                    char_count += 1\n            \n            text_len = len(s)\n            return Vectors.dense(text_len, char_count, \n                                 uppercase_count, uppercase_count / (char_count + 1e-10))\n\n        return dataset.withColumn(self.getOutputCol(), \n                                  F.udf(f, VectorUDT())(dataset[self.getInputCol()]))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\n# customized transformer class to manually extract some counting based word features\nclass ReviewWordsTransformer(Transformer, HasInputCol, HasOutputCol):\n\n    @keyword_only\n    def __init__(self, inputCol=\"content\", outputCol=\"content_features\"):\n        super(ReviewWordsTransformer, self).__init__()\n        kwargs = self._input_kwargs\n        self.setParams(**kwargs)\n\n    @keyword_only\n    def setParams(self, inputCol=None, outputCol=None):\n        kwargs = self._input_kwargs\n        return self._set(**kwargs)\n\n\n    def _transform(self, dataset):\n        \n        def f(words):    \n            word_count = len(words)\n            unique_word_count = len(set(words))\n            upper_words = []\n            for w in words:\n                if w.isupper():\n                    upper_words.append(w)\n            upper_word_count = len(set(upper_words))\n            unique_upper_word_count = len(upper_words)\n            return Vectors.dense(word_count, unique_word_count, unique_word_count / (word_count + 1e-10),\n                                 upper_word_count, upper_word_count / (word_count + 1e-10), \n                                 unique_upper_word_count, unique_upper_word_count / (upper_word_count + 1e-10))\n\n        return dataset.withColumn(self.getOutputCol(), \n                                  F.udf(f, VectorUDT())(dataset[self.getInputCol()]))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\n# show model prediction performance on the given dataset\ndef eval_model_perf(fitted_model, dataset, label_col=\"label\", prediction_col=\"prediction\", probability_col=\"probability\"):\n    pred_dataset = fitted_model.transform(dataset)\n    eval_dataset = pred_dataset.select(label_col, prediction_col, probability_col)\n    # model performance evaluation\n    metricNames = [\"accuracy\", \"f1\"]\n    model_eval = MulticlassClassificationEvaluator(predictionCol=prediction_col, labelCol=label_col)\n    for m in metricNames:\n        val = model_eval.evaluate(eval_dataset, {model_eval.metricName: m})\n        print(m, \" = \", val)\n    roc_eval = BinaryClassificationEvaluator(rawPredictionCol=probability_col, labelCol=label_col, metricName=\"areaUnderROC\")\n    print(\"AUC =\", roc_eval.evaluate(eval_dataset))    \n    return pred_dataset\n\n# show CV param tunning result\ndef show_cv_results(cv_model):\n    for result, param in sorted(zip(cv_model.avgMetrics, cv_model.getEstimatorParamMaps()), reverse=True, key=lambda x: x[0]):\n        print(result, \" | \", param)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\ndef run_models(df_train, df_test, without_pca = False):\n    print(\"**********LogisticRegression**********\")\n    t = time.time()\n    lr_model = LogisticRegression(featuresCol='features', \n                                  labelCol='label', \n                                  predictionCol='prediction', \n                                  probabilityCol='probability', \n                                  rawPredictionCol='rawPrediction',\n                                  family='binomial', \n                                  fitIntercept=True, \n                                  threshold=0.5, \n                                  standardization=False, \n                                  maxIter=200, \n                                  regParam=0.005, \n                                  elasticNetParam=0, \n                                  tol=1e-06, \n                                  aggregationDepth=2)\n\n    lr_model = lr_model.fit(df_train)\n    \n    eval_model_perf(lr_model, df_test)\n    \n    print(\"time taken for LogisticRegression: \", time.time() - t)\n    t = time.time()\n\n    print(\"**********DecisionTreeClassifier**********\")\n    dt_model = DecisionTreeClassifier(featuresCol='features', \n                                      labelCol='label', \n                                      predictionCol='prediction', \n                                      probabilityCol='probability', \n                                      rawPredictionCol='rawPrediction', \n                                      maxDepth=10, maxBins=32, \n                                      minInstancesPerNode=1, \n                                      minInfoGain=0.0, \n                                      maxMemoryInMB=2048, \n                                      cacheNodeIds=True, \n                                      checkpointInterval=10,\n                                      impurity='gini', \n                                      seed=666)\n\n    dt_model = dt_model.fit(df_train)\n    eval_model_perf(dt_model, df_test)\n    print(\"time taken for DecisionTreeClassifier: \", time.time() - t)\n    t = time.time()\n    \n    print(\"**********RandomForestClassifier**********\")\n    rf_model = RandomForestClassifier(featuresCol='features', \n                                      labelCol='label', \n                                      predictionCol='prediction', \n                                      probabilityCol='probability', \n                                      rawPredictionCol='rawPrediction',\n                                      maxDepth=10, \n                                      maxBins=32, \n                                      minInstancesPerNode=1, \n                                      minInfoGain=0.0, \n                                      maxMemoryInMB=2048, \n                                      cacheNodeIds=True, \n                                      checkpointInterval=10, \n                                      impurity='gini', \n                                      numTrees=200, \n                                      featureSubsetStrategy='auto', \n                                      seed=666, \n                                      subsamplingRate=0.8)\n\n    rf_model = rf_model.fit(df_train)\n    eval_model_perf(rf_model, df_test)\n    print(\"time taken for RandomForestClassifier: \", time.time() - t)\n    t = time.time()\n    \n    print(\"**********GBTClassifier**********\")\n    gbt_model = GBTClassifier(featuresCol='features', \n                             labelCol='label', \n                             maxIter=250)\n\n    gbt_model = gbt_model.fit(df_train)\n    eval_model_perf(gbt_model, df_test)\n    print(\"time taken for GBTClassifier: \", time.time() - t)\n    t = time.time()    \n    \n    print(\"**********MultilayerPerceptronClassifier**********\")\n    mp_model = MultilayerPerceptronClassifier(featuresCol='features', \n                                              labelCol='label', \n                                              predictionCol='prediction', \n                                              layers=[4, 5, 4, 3],  \n                                              maxIter=100, \n                                              blockSize=128, \n                                              seed=1234)\n\n    mp_model = mp_model.fit(df_train)\n    eval_model_perf(mp_model, df_test)\n    print(\"time taken for MultilayerPerceptronClassifier: \", time.time() - t)\n    t = time.time() \n    \n    if without_pca:\n        print(\"**********NaiveBayes**********\")\n        nb_model = NaiveBayes(featuresCol='features', \n                              labelCol='label', \n                              predictionCol='prediction', \n                              probabilityCol='probability', \n                              rawPredictionCol='rawPrediction', \n                              smoothing=1, \n                              modelType='multinomial')\n\n        nb_model = mp_model.fit(df_train)\n        eval_model_perf(nb_model, df_test)\n        print(\"time taken for NaiveBayes: \", time.time() - t)    "}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\ndef build_data_preproc_model_with_pca(vocab_size=5000):\n    preproc_steps = [\n        RegexTokenizer(inputCol=\"content\", outputCol=\"all_words\", pattern=r\"\\W\"),\n        StopWordsRemover(inputCol=\"all_words\", outputCol=\"words\"),\n        CountVectorizer(inputCol=\"words\", outputCol=\"tf_features\", vocabSize=vocab_size),\n        IDF(inputCol=\"tf_features\", outputCol=\"tfidf_features\"),\n        PCA(inputCol=\"tfidf_features\", outputCol=\"pca_features\", k=100),\n        ReviewContentTransformer(inputCol=\"content\", outputCol=\"content_features\"),\n        ReviewWordsTransformer(inputCol=\"words\", outputCol=\"word_features\"),\n        VectorAssembler(inputCols=[\"pca_features\", \"content_features\", \"word_features\"], \n                        outputCol=\"features\")\n    ]\n    return Pipeline(stages=preproc_steps)\n\ndef build_data_preproc_model_without_pca(vocab_size=5000):\n    preproc_steps = [\n        RegexTokenizer(inputCol=\"content\", outputCol=\"all_words\", pattern=r\"\\W\"),\n        StopWordsRemover(inputCol=\"all_words\", outputCol=\"words\"),\n        CountVectorizer(inputCol=\"words\", outputCol=\"tf_features\", vocabSize=vocab_size),\n        IDF(inputCol=\"tf_features\", outputCol=\"tfidf_features\"),\n        ReviewContentTransformer(inputCol=\"content\", outputCol=\"content_features\"),\n        ReviewWordsTransformer(inputCol=\"words\", outputCol=\"word_features\"),\n        VectorAssembler(inputCols=[\"content_features\", \"word_features\"], outputCol=\"features\")\n    ]\n    return Pipeline(stages=preproc_steps)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\nprint(\"**********Run Models with PCA Features**********\")\n# generate the features to be used for model training\npreproc_model = build_data_preproc_model_with_pca(2000).fit(df_train)\ndf_train_pca = preproc_model.transform(df_train).select(\"label\", \"features\")\nprint(df_train_pca.take(1))\ndf_test_pca = preproc_model.transform(df_test).select(\"label\", \"features\")\nprint(df_test_pca.take(1))\nrun_models(df_train_pca, df_test_pca)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "%%time\nprint(\"**********Run Models without PCA Features**********\")\n# generate the features to be used for model training\npreproc_model = build_data_preproc_model_without_pca(3000).fit(df_train)\ndf_train_wo_pca = preproc_model.transform(df_train).select(\"label\", \"features\")\nprint(df_train_wo_pca.take(1))\ndf_test_wo_pca = preproc_model.transform(df_test).select(\"label\", \"features\")\nprint(df_test_wo_pca.take(1))\nrun_models(df_train_wo_pca, df_test_wo_pca, without_pca = True)"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.10"}}, "nbformat": 4, "nbformat_minor": 2}