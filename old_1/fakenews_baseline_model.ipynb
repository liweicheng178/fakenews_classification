{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14\n",
      "CPU times: user 68.3 ms, sys: 12.8 ms, total: 81.1 ms\n",
      "Wall time: 74.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import os, sys, time, json, re, string\n",
    "\n",
    "from pyspark import SparkContext, SparkConf, StorageLevel, keyword_only\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.param.shared import HasInputCol, HasInputCols, HasOutputCol, HasOutputCols, Param\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer, NGram, CountVectorizer, StopWordsRemover\n",
    "from pyspark.ml.feature import VectorAssembler, PCA\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cluster-fe4d-m.asia-southeast1-a.c.weicheng.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 ms, sys: 7.84 ms, total: 9.86 ms\n",
      "Wall time: 14.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"fakenews_baseline_model_with_pca\") \\\n",
    "        .config(\"spark.master\", \"yarn\") \\\n",
    "        .config(\"spark.submit.deployMode\", \"cluster\") \\\n",
    "        .config(\"spark.driver.memory\", \"15g\") \\\n",
    "        .config(\"spark.executor.instances\", \"5\") \\\n",
    "        .config(\"spark.executor.cores\", \"4\") \\\n",
    "        .config(\"spark.executor.memory\", \"10g\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 ms, sys: 5.19 ms, total: 19.1 ms\n",
      "Wall time: 8.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fakenews_path=\"gs://dataproc-6ca41800-27b4-47d5-abee-55c011dfa389-asia-southeast1/data/fake-news/\"\n",
    "fakenews_data_path = fakenews_path + \"two_million_rows_news_cleaned_2018_02_13_pyspark.csv\"\n",
    "df_news = spark.read.format(\"com.databricks.spark.csv\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"delimiter\", '#') \\\n",
    "                    .load(fakenews_data_path)\n",
    "\n",
    "# only keep type and content\n",
    "df_news = df_news.select(\"type\", \"content\", \"domain\")\n",
    "# add binary label\n",
    "df_news = df_news.withColumn(\"label\", F.when(F.col(\"type\") == 'fake', 1).otherwise(0))\n",
    "\n",
    "#remove empty content which will cause problem when transform the text\n",
    "df_news = df_news.filter(df_news.content != \"\")\n",
    "\n",
    "#facing out of memory issue in google cluster for 5 instance * 15 GB, so sampling with 10K fake news and non-fake news\n",
    "row_count = 10000\n",
    "df_news_fake = df_news.filter(df_news.type == 'fake').limit(row_count)\n",
    "df_news_nonfake = df_news.filter(df_news.type != 'fake').limit(row_count)\n",
    "df_news = df_news_fake.union(df_news_nonfake)\n",
    "\n",
    "# split the dataset\n",
    "df_train, df_test = df_news.randomSplit([0.8, 0.2], seed=666)\n",
    "\n",
    "param_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 157 µs, sys: 30 µs, total: 187 µs\n",
      "Wall time: 145 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# customized transformer class to manually extract some counting based text features\n",
    "class ReviewContentTransformer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=\"content\", outputCol=\"content_features\"):\n",
    "        super(ReviewContentTransformer, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        @udf('double')\n",
    "        def f(s):\n",
    "            uppercase_count = 0\n",
    "            char_count = 0\n",
    "            for c in s:                \n",
    "                if c in string.ascii_uppercase:\n",
    "                    uppercase_count += 1\n",
    "                    char_count += 1\n",
    "                elif c in string.ascii_lowercase:\n",
    "                    char_count += 1\n",
    "            \n",
    "            text_len = len(s)\n",
    "            return Vectors.dense(text_len, char_count, \n",
    "                                 uppercase_count, uppercase_count / (char_count + 1e-10))\n",
    "\n",
    "        return dataset.withColumn(self.getOutputCol(), \n",
    "                                  F.udf(f, VectorUDT())(dataset[self.getInputCol()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 µs, sys: 31 µs, total: 197 µs\n",
      "Wall time: 163 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# customized transformer class to manually extract some counting based word features\n",
    "class ReviewWordsTransformer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=\"content\", outputCol=\"content_features\"):\n",
    "        super(ReviewWordsTransformer, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        \n",
    "        def f(words):    \n",
    "            word_count = len(words)\n",
    "            unique_word_count = len(set(words))\n",
    "            upper_words = []\n",
    "            for w in words:\n",
    "                if w.isupper():\n",
    "                    upper_words.append(w)\n",
    "            upper_word_count = len(set(upper_words))\n",
    "            unique_upper_word_count = len(upper_words)\n",
    "            return Vectors.dense(word_count, unique_word_count, unique_word_count / (word_count + 1e-10),\n",
    "                                 upper_word_count, upper_word_count / (word_count + 1e-10), \n",
    "                                 unique_upper_word_count, unique_upper_word_count / (upper_word_count + 1e-10))\n",
    "\n",
    "        return dataset.withColumn(self.getOutputCol(), \n",
    "                                  F.udf(f, VectorUDT())(dataset[self.getInputCol()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# show model prediction performance on the given dataset\n",
    "def eval_model_perf(fitted_model, dataset, label_col=\"label\", prediction_col=\"prediction\", probability_col=\"probability\"):\n",
    "    pred_dataset = fitted_model.transform(dataset)\n",
    "    eval_dataset = pred_dataset.select(label_col, prediction_col, probability_col)\n",
    "    # model performance evaluation\n",
    "    metricNames = [\"accuracy\", \"f1\"]\n",
    "    model_eval = MulticlassClassificationEvaluator(predictionCol=prediction_col, labelCol=label_col)\n",
    "    for m in metricNames:\n",
    "        val = model_eval.evaluate(eval_dataset, {model_eval.metricName: m})\n",
    "        print(m, \" = \", val)\n",
    "    roc_eval = BinaryClassificationEvaluator(rawPredictionCol=probability_col, labelCol=label_col, metricName=\"areaUnderROC\")\n",
    "    print(\"AUC =\", roc_eval.evaluate(eval_dataset))    \n",
    "    return pred_dataset\n",
    "\n",
    "# show CV param tunning result\n",
    "def show_cv_results(cv_model):\n",
    "    for result, param in sorted(zip(cv_model.avgMetrics, cv_model.getEstimatorParamMaps()), reverse=True, key=lambda x: x[0]):\n",
    "        print(result, \" | \", param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def run_models(df_train, df_test):\n",
    "    print(\"**********LogisticRegression**********\")\n",
    "    t = time.time()\n",
    "    lr_model = LogisticRegression(featuresCol='features', \n",
    "                                  labelCol='label', \n",
    "                                  predictionCol='prediction', \n",
    "                                  probabilityCol='probability', \n",
    "                                  rawPredictionCol='rawPrediction',\n",
    "                                  family='binomial', \n",
    "                                  fitIntercept=True, \n",
    "                                  threshold=0.5, \n",
    "                                  standardization=False, \n",
    "                                  maxIter=200, \n",
    "                                  regParam=0.005, \n",
    "                                  elasticNetParam=0, \n",
    "                                  tol=1e-06, \n",
    "                                  aggregationDepth=2)\n",
    "\n",
    "    lr_model = lr_model.fit(df_train)\n",
    "    \n",
    "    eval_model_perf(lr_model, df_test)\n",
    "    \n",
    "    print(\"time taken for LogisticRegression: \", time.time() - t)\n",
    "    t = time.time()\n",
    "\n",
    "    # BELOW CODE IS USED ONLY FOR PARAM TUNNING\n",
    "    # # grid search params tunning\n",
    "    # paramGrid = ParamGridBuilder() \\\n",
    "    #     .addGrid(lr_model.regParam, [0.001, 0.005]) \\\n",
    "    #     .addGrid(lr_model.standardization, [False, True]) \\\n",
    "    #     .build()\n",
    "    # # cross validator model\n",
    "    # crossval = CrossValidator(estimator=lr_model, \n",
    "    # #                           evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
    "    #                           evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"probability\", labelCol=\"label\", metricName=\"areaUnderROC\"),\n",
    "    #                           estimatorParamMaps=paramGrid,\n",
    "    #                           numFolds=2, parallelism = 2,\n",
    "    #                           seed=666)\n",
    "    # # run it!\n",
    "    # crossval_model = crossval.fit(df_train)\n",
    "    # # evaluate performance\n",
    "    # show_cv_results(crossval_model)\n",
    "    # eval_model_perf(crossval_model, df_test)\n",
    "    # selected_model = crossval_model.bestModel\n",
    "    # print(selected_model.explainParams())\n",
    "    print(\"**********DecisionTreeClassifier**********\")\n",
    "    dt_model = DecisionTreeClassifier(featuresCol='features', \n",
    "                                      labelCol='label', \n",
    "                                      predictionCol='prediction', \n",
    "                                      probabilityCol='probability', \n",
    "                                      rawPredictionCol='rawPrediction', \n",
    "                                      maxDepth=10, maxBins=32, \n",
    "                                      minInstancesPerNode=1, \n",
    "                                      minInfoGain=0.0, \n",
    "                                      maxMemoryInMB=2048, \n",
    "                                      cacheNodeIds=True, \n",
    "                                      checkpointInterval=10,\n",
    "                                      impurity='gini', \n",
    "                                      seed=666)\n",
    "\n",
    "    dt_model = dt_model.fit(df_train)\n",
    "    eval_model_perf(dt_model, df_test)\n",
    "    print(\"time taken for DecisionTreeClassifier: \", time.time() - t)\n",
    "    t = time.time()\n",
    "    \n",
    "    print(\"**********RandomForestClassifier**********\")\n",
    "    rf_model = RandomForestClassifier(featuresCol='features', \n",
    "                                      labelCol='label', \n",
    "                                      predictionCol='prediction', \n",
    "                                      probabilityCol='probability', \n",
    "                                      rawPredictionCol='rawPrediction',\n",
    "                                      maxDepth=10, \n",
    "                                      maxBins=32, \n",
    "                                      minInstancesPerNode=1, \n",
    "                                      minInfoGain=0.0, \n",
    "                                      maxMemoryInMB=2048, \n",
    "                                      cacheNodeIds=True, \n",
    "                                      checkpointInterval=10, \n",
    "                                      impurity='gini', \n",
    "                                      numTrees=200, \n",
    "                                      featureSubsetStrategy='auto', \n",
    "                                      seed=666, \n",
    "                                      subsamplingRate=0.8)\n",
    "\n",
    "    rf_model = rf_model.fit(df_train)\n",
    "    eval_model_perf(rf_model, df_test)\n",
    "    print(\"time taken for RandomForestClassifier: \", time.time() - t)\n",
    "    t = time.time()\n",
    "    \n",
    "    print(\"**********GBTClassifier**********\")\n",
    "    gbt_model = GBTClassifier(featuresCol='features', \n",
    "                             labelCol='label', \n",
    "                             maxIter=250)\n",
    "\n",
    "    gbt_model = gbt_model.fit(df_train)\n",
    "    eval_model_perf(gbt_model, df_test)\n",
    "    print(\"time taken for GBTClassifier: \", time.time() - t)\n",
    "    t = time.time()    \n",
    "    \n",
    "    print(\"**********MultilayerPerceptronClassifier**********\")\n",
    "    mp_model = MultilayerPerceptronClassifier(featuresCol='features', \n",
    "                                              labelCol='label', \n",
    "                                              predictionCol='prediction', \n",
    "                                              layers=[4, 5, 4, 3],  \n",
    "                                              maxIter=100, \n",
    "                                              blockSize=128, \n",
    "                                              seed=1234)\n",
    "\n",
    "    mp_model = mp_model.fit(df_train)\n",
    "    eval_model_perf(rf_model, df_test)\n",
    "    print(\"time taken for MultilayerPerceptronClassifier: \", time.time() - t)\n",
    "    t = time.time()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 µs, sys: 6 µs, total: 31 µs\n",
      "Wall time: 26 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def build_data_preproc_model_with_pca(vocab_size=5000):\n",
    "    preproc_steps = [\n",
    "        RegexTokenizer(inputCol=\"content\", outputCol=\"all_words\", pattern=r\"\\W\"),\n",
    "        StopWordsRemover(inputCol=\"all_words\", outputCol=\"words\"),\n",
    "        CountVectorizer(inputCol=\"words\", outputCol=\"tf_features\", vocabSize=vocab_size),\n",
    "        IDF(inputCol=\"tf_features\", outputCol=\"tfidf_features\"),\n",
    "        PCA(inputCol=\"tfidf_features\", outputCol=\"pca_features\", k=100),\n",
    "        ReviewContentTransformer(inputCol=\"content\", outputCol=\"content_features\"),\n",
    "        ReviewWordsTransformer(inputCol=\"words\", outputCol=\"word_features\"),\n",
    "        VectorAssembler(inputCols=[\"pca_features\", \"content_features\", \"word_features\"], \n",
    "                        outputCol=\"features\")\n",
    "    ]\n",
    "    return Pipeline(stages=preproc_steps)\n",
    "\n",
    "def build_data_preproc_model_without_pca(vocab_size=5000):\n",
    "    preproc_steps = [\n",
    "        RegexTokenizer(inputCol=\"content\", outputCol=\"all_words\", pattern=r\"\\W\"),\n",
    "        StopWordsRemover(inputCol=\"all_words\", outputCol=\"words\"),\n",
    "        CountVectorizer(inputCol=\"words\", outputCol=\"tf_features\", vocabSize=vocab_size),\n",
    "        IDF(inputCol=\"tf_features\", outputCol=\"tfidf_features\"),\n",
    "        ReviewContentTransformer(inputCol=\"content\", outputCol=\"content_features\"),\n",
    "        ReviewWordsTransformer(inputCol=\"words\", outputCol=\"word_features\"),\n",
    "        VectorAssembler(inputCols=[\"content_features\", \"word_features\"], outputCol=\"features\")\n",
    "    ]\n",
    "    return Pipeline(stages=preproc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Run Models with PCA Features**********\n",
      "[Row(label=1, features=DenseVector([-2.1915, 6.3671, 5.9627, -0.8709, 1.7528, 0.2703, -2.211, 0.1734, -1.3007, 2.6581, -1.0847, -0.4082, -0.4743, 2.7807, -1.449, 0.0731, -1.0452, -1.0414, -0.047, -0.1921, 0.0957, -1.3617, -0.6802, -1.5515, 1.0233, -0.8923, -1.9182, 0.0896, -0.2538, -0.9743, -0.0991, -0.4519, -0.0602, 0.0667, -0.1877, -0.2286, -0.6194, -0.144, -1.5133, -0.9174, 2.2229, 0.2836, -0.4546, 0.5312, -0.5634, -1.3333, -2.0026, -0.2667, -0.2825, -0.1634, 1.0971, -0.9532, -0.2814, 0.3173, 0.6294, 0.9068, 0.823, 0.4273, 1.9517, -0.3337, -0.4679, 0.6075, 0.6886, -0.8593, 1.4042, 0.4806, -1.6286, 0.0083, 1.3086, -1.5275, -0.8785, -0.8087, 0.653, 0.7002, 0.7796, 0.6142, 0.4945, 0.2033, 0.187, -0.1564, 0.3701, 0.4724, -0.0621, 1.0945, -0.204, -0.1006, -1.3995, -1.1552, 0.3147, 0.551, -0.1518, 0.0239, 0.576, -2.3285, 0.7232, -1.1511, -0.8845, 1.2424, -0.192, 0.9256, 3298.0, 2585.0, 59.0, 0.0228, 273.0, 249.0, 0.9121, 0.0, 0.0, 0.0, 0.0]))]\n",
      "[Row(label=1, features=DenseVector([-0.6781, 1.3961, 1.0217, -0.2395, 0.2503, 0.0607, -0.3789, 0.098, -0.0737, 0.1469, -0.6153, 0.0428, -0.0289, -0.1529, 0.1565, 0.0225, -0.1016, 0.3226, -0.1993, 0.0859, 0.2042, -0.1586, -0.4823, -0.2333, 0.4369, -0.1602, -0.5275, 0.1026, -0.3391, -0.3838, -0.5224, 0.2389, -0.8658, 0.2904, 0.0572, -0.0104, 0.1633, -0.1858, 0.5147, 0.0475, -0.0623, 0.1622, -0.1927, 0.1892, 0.1405, -0.0657, -0.1558, 0.2788, 0.055, 0.0545, -0.0933, 0.1162, 0.3768, 0.0877, -0.2992, 0.1646, 0.5212, -0.2439, 0.9182, -0.0659, -0.1034, -0.3428, -0.0589, 0.1773, 0.0538, -0.4785, -0.687, 0.1188, -0.2889, -0.1764, 0.1139, 0.2637, 0.142, -0.1699, -0.5311, 0.5231, -0.4938, 0.2929, -0.4007, -0.1723, 0.1096, -0.4889, -0.7202, 0.5145, 0.5037, 0.0043, -0.0754, 0.606, 0.1152, 0.2038, -0.039, 0.3515, 0.3534, -0.4538, 0.1363, -0.2786, 0.3768, -0.433, -0.5116, -0.2667, 865.0, 659.0, 45.0, 0.0683, 82.0, 64.0, 0.7805, 0.0, 0.0, 0.0, 0.0]))]\n",
      "**********LogisticRegression**********\n",
      "('accuracy', ' = ', 0.7427437360456463)\n",
      "('f1', ' = ', 0.7591798865036208)\n",
      "('AUC =', 0.6813275504524333)\n",
      "('time taken for LogisticRegression: ', 125.60507416725159)\n",
      "**********DecisionTreeClassifier**********\n",
      "('accuracy', ' = ', 0.592904986355743)\n",
      "('f1', ' = ', 0.6259111912319472)\n",
      "('AUC =', 0.5314269283247871)\n",
      "('time taken for DecisionTreeClassifier: ', 199.94605088233948)\n",
      "**********RandomForestClassifier**********\n",
      "('accuracy', ' = ', 0.8129496402877698)\n",
      "('f1', ' = ', 0.8382285554149425)\n",
      "('AUC =', 0.7560353277868911)\n",
      "('time taken for RandomForestClassifier: ', 260.00016498565674)\n",
      "**********GBTClassifier**********\n",
      "('accuracy', ' = ', 0.5839741999503845)\n",
      "('f1', ' = ', 0.7524615333996953)\n",
      "('AUC =', 0.8793949155965348)\n",
      "('time taken for GBTClassifier: ', 660.4286921024323)\n",
      "**********MultilayerPerceptronClassifier**********\n",
      "('accuracy', ' = ', 0.840238154304143)\n",
      "('f1', ' = ', 0.7268267693002368)\n",
      "('AUC =', 0.7264286030943856)\n",
      "('time taken for MultilayerPerceptronClassifier: ', 121.49153590202332)\n",
      "CPU times: user 1.31 s, sys: 384 ms, total: 1.7 s\n",
      "Wall time: 25min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"**********Run Models with PCA Features**********\")\n",
    "# generate the features to be used for model training\n",
    "preproc_model = build_data_preproc_model_with_pca(2000).fit(df_train)\n",
    "df_train_pca = preproc_model.transform(df_train).select(\"label\", \"features\")\n",
    "print(df_train_pca.take(1))\n",
    "df_test_pca = preproc_model.transform(df_test).select(\"label\", \"features\")\n",
    "print(df_test_pca.take(1))\n",
    "run_models(df_train_pca, df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Run Models without PCA Features**********\n",
      "[Row(label=1, features=DenseVector([2590.0, 2018.0, 99.0, 0.0491, 230.0, 142.0, 0.6174, 0.0, 0.0, 0.0, 0.0]))]\n",
      "[Row(label=1, features=DenseVector([6372.0, 5076.0, 125.0, 0.0246, 565.0, 360.0, 0.6372, 0.0, 0.0, 0.0, 0.0]))]\n",
      "('accuracy', ' = ', 0.5829818903497891)\n",
      "('f1', ' = ', 0.5803263922596662)\n",
      "('AUC =', 0.7026301271347141)\n",
      "CPU times: user 206 ms, sys: 79.1 ms, total: 285 ms\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"**********Run Models without PCA Features**********\")\n",
    "# generate the features to be used for model training\n",
    "preproc_model = build_data_preproc_model_without_pca(2000).fit(df_train)\n",
    "df_train_wo_pca = preproc_model.transform(df_train).select(\"label\", \"features\")\n",
    "print(df_train_wo_pca.take(1))\n",
    "df_test_wo_pca = preproc_model.transform(df_test).select(\"label\", \"features\")\n",
    "print(df_test_wo_pca.take(1))\n",
    "\n",
    "nb_model = NaiveBayes(featuresCol='features', \n",
    "                      labelCol='label', \n",
    "                      predictionCol='prediction', \n",
    "                      probabilityCol='probability', \n",
    "                      rawPredictionCol='rawPrediction', \n",
    "                      smoothing=1, \n",
    "                      modelType='multinomial')\n",
    "\n",
    "nb_model = nb_model.fit(df_train_wo_pca)\n",
    "eval_model_perf(nb_model, df_test_wo_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
